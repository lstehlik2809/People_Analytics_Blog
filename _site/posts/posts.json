[
  {
    "path": "posts/2020-12-31-segmentedregression/",
    "title": "Modeling Impact of the COVID-19 Pandemic on People’s Interest in Work-Life Balance and Well-Being",
    "description": "Illustration of Bayesian segmented regression analysis of interrupted time series data with a testing hypothesis about the impact of the COVID-19 pandemic on increase in people's search interest in work-life balance and well-being.",
    "author": [
      {
        "name": "Ludek Stehlík",
        "url": "https://www.linkedin.com/in/ludekstehlik/"
      }
    ],
    "date": "2020-12-31",
    "categories": [
      "segmented regression",
      "interrupted time series data",
      "bayesian inference",
      "brms",
      "r",
      "well-being & work-life balance"
    ],
    "contents": "\r\nThe turn of the year, which is full of all sorts of resolutions to change for the better in our private lives and in our organizations, is a good time to remind ourselves that analytic tools can be very helpful in our efforts to make these resolutions come true. One way they can help us is by verifying that we have really achieved our stated goals and that we are not just fooling ourselves into believing so. We need to keep in mind Richard Feynman’s famous principle of critical thinking…\r\n\r\n\r\nOne of the tools that can help us with that is segmented regression analysis of interrupted time series data (thanks to Masatake Hirono for pointing me to its existence). It allows us to model changes in various processes and outcomes that follow interventions, while controlling for other types of changes (e.g. trends and seasonality) that may have occurred regardless of the interventions. It is thus very useful for data analysis conducted within studies with a quasi experimental study design that are often in the organizational context the best alternative to the “gold standard” of randomized controlled trials (RCTs) that are not always realizable or politically acceptable.\r\nFor illustration, let’s use this tool for testing hypothesis about people’s increased interest in topics related to work-life balance and well-being due to the COVID-19 pandemic and subsequent changes in the way people work. As a proxy measure of this interest we will use worldwide search interest data over the last 10 years from Google Trends using search terms work-life balance and well-being (see Fig. 1 and 2 below).\r\nFig. 1: Interest in “work-life balance” topic over the last 10 years measured as a search interest by Google Trends. The numbers represent search interest relative to the highest point on the chart for the given region and time. A value of 100 is the peak popularity for the term. A value of 50 means that the term is half as popular. A score of 0 means that there was not enough data for this term.\r\n\r\nFig. 2: Interest in “well-being” topic over the last 10 years measured as a search interest by Google Trends. The numbers represent search interest relative to the highest point on the chart for the given region and time. A value of 100 is the peak popularity for the term. A value of 50 means that the term is half as popular. A score of 0 means that there was not enough data for this term.\r\n\r\nBased solely on the visual inspection of the graphs, it is pretty difficult to tell whether there was some effect of the COVID-19 pandemic or not, especially in the case of work-life balance (for the purpose of this analysis, the beginning of the pandemic is assumed to have started in March 2020). For sure it’s not a job for “inter-ocular trauma test” when the existence of the effect hits you directly between the eyes. We need to rely here on inferential statistics and its ability to help us with distinguishing signal from noise.\r\nBefore conducting the analysis itself, we need to wrangle the data from Google Trends a little bit using the recipe presented in the Wagner, Zhang, and Ross-Degnan’s paper. Specifically, we need the following five variables (or six, given that we have two dependent variables):\r\nsearch interest – numerical variable representing search interest relative to the highest point on the chart for the given region and time; this variable is truncated within the interval between values of 0 and 100; a value of 100 is the peak popularity for the term; a value of 50 means that the term is half as popular; a score of 0 means that there was not enough data for this term; this variable serves as a dependent (criterion) variable;\r\nelapsed time – numerical variable representing the number of months that elapsed from the beginning of the time series; this variable enables estimation of the size and direction of the overall trend in the data;\r\npandemic – dichotomic variable indicating the presence/absence of pandemic; as already mentioned above, for the purpose of this analysis, the beginning of the pandemic is assumed to have started in March 2020; this variable enables testing hypothesis about the effect of pandemic on people’s interest in work-life balance and well-being;\r\nelapsed time after pandemic onset – numerical variable representing the number of months that elapsed from the beginning of pandemic; this variable enables estimation of the size and direction of the trend in the data after the onset of pandemic;\r\nmonth – categorical variable representing specific month within a year; this variable enables controlling for the effect of seasonality.\r\n\r\n\r\n# uploading library for data manipulation\r\nlibrary(tidyverse)\r\n\r\n# uploading data\r\ndfWorkLifeBalance <- readr::read_csv(\"./workLifeBalanceGoogleTrendData.csv\")\r\ndfWellBeing <- readr::read_csv(\"./wellBeingGoogleTrendData.csv\")\r\n\r\ndfAll <- dfWorkLifeBalance %>%\r\n  # joining both datasets\r\n  dplyr::left_join(\r\n    dfWellBeing, by = \"Month\"\r\n    ) %>%\r\n  # changing the format and name of Month variable\r\n  dplyr::mutate(\r\n    Month = stringr::str_glue(\"{Month}-01\"),\r\n    Month = lubridate::ymd(Month)\r\n    ) %>%\r\n  dplyr::rename(\r\n    date = Month\r\n    ) %>%\r\n  # creating new variable month\r\n  dplyr::mutate(\r\n    month = lubridate::month(date,label = TRUE, abbr = TRUE),\r\n    month = factor(month, \r\n                   levels = c(\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"), \r\n                   labels = c(\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\", \"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"), \r\n                   ordered = FALSE)\r\n    ) %>%\r\n  # arranging data in ascending order by date\r\n  dplyr::arrange(\r\n    date\r\n    ) %>%\r\n  # creating new variables\r\n  dplyr::mutate(\r\n    elapsedTime = row_number(),\r\n    pandemic = case_when(\r\n      date >= '2020-03-01' ~ 1,\r\n      TRUE ~ 0\r\n      ),\r\n    elapsedTimeAfterPandemic = cumsum(pandemic)\r\n    ) %>%\r\n  # changing order of variables in df\r\n  dplyr::select(\r\n    date, workLifeBalance, wellBeing, elapsedTime, month, pandemic, elapsedTimeAfterPandemic\r\n    )\r\n\r\n\r\n\r\n\r\nHere is a table with the resulting data we will use for testing our hypothesis.\r\n\r\n\r\n# uploading library for making user-friendly data table\r\nlibrary(DT)\r\n\r\nDT::datatable(\r\n  dfAll,\r\n  class = 'cell-border stripe', \r\n  filter = 'top',\r\n  extensions = 'Buttons',\r\n  fillContainer = FALSE,\r\n  options = list(\r\n    pageLength = 5, \r\n    autoWidth = TRUE,\r\n    dom = 'Bfrtip',\r\n    buttons = c('copy'), \r\n    scrollX = TRUE, \r\n    selection=\"multiple\"\r\n    )\r\n  )\r\n\r\n\r\n\r\n{\"x\":{\"filter\":\"top\",\"filterHTML\":\"<tr>\\n  <td><\\/td>\\n  <td data-type=\\\"date\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none; position: absolute; width: 200px;\\\">\\n      <div data-min=\\\"1.262304e+12\\\" data-max=\\\"1606780800000\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"number\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none; position: absolute; width: 200px;\\\">\\n      <div data-min=\\\"19\\\" data-max=\\\"100\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"number\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none; position: absolute; width: 200px;\\\">\\n      <div data-min=\\\"22\\\" data-max=\\\"100\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"integer\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none; position: absolute; width: 200px;\\\">\\n      <div data-min=\\\"1\\\" data-max=\\\"132\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"factor\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"width: 100%; display: none;\\\">\\n      <select multiple=\\\"multiple\\\" style=\\\"width: 100%;\\\" data-options=\\\"[&quot;Jan&quot;,&quot;Feb&quot;,&quot;Mar&quot;,&quot;Apr&quot;,&quot;May&quot;,&quot;Jun&quot;,&quot;Jul&quot;,&quot;Aug&quot;,&quot;Sep&quot;,&quot;Oct&quot;,&quot;Nov&quot;,&quot;Dec&quot;]\\\"><\\/select>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"number\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none; position: absolute; width: 200px;\\\">\\n      <div data-min=\\\"0\\\" data-max=\\\"1\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"number\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none; position: absolute; width: 200px;\\\">\\n      <div data-min=\\\"0\\\" data-max=\\\"10\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n<\\/tr>\",\"extensions\":[\"Buttons\"],\"fillContainer\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\"],[\"2010-01-01\",\"2010-02-01\",\"2010-03-01\",\"2010-04-01\",\"2010-05-01\",\"2010-06-01\",\"2010-07-01\",\"2010-08-01\",\"2010-09-01\",\"2010-10-01\",\"2010-11-01\",\"2010-12-01\",\"2011-01-01\",\"2011-02-01\",\"2011-03-01\",\"2011-04-01\",\"2011-05-01\",\"2011-06-01\",\"2011-07-01\",\"2011-08-01\",\"2011-09-01\",\"2011-10-01\",\"2011-11-01\",\"2011-12-01\",\"2012-01-01\",\"2012-02-01\",\"2012-03-01\",\"2012-04-01\",\"2012-05-01\",\"2012-06-01\",\"2012-07-01\",\"2012-08-01\",\"2012-09-01\",\"2012-10-01\",\"2012-11-01\",\"2012-12-01\",\"2013-01-01\",\"2013-02-01\",\"2013-03-01\",\"2013-04-01\",\"2013-05-01\",\"2013-06-01\",\"2013-07-01\",\"2013-08-01\",\"2013-09-01\",\"2013-10-01\",\"2013-11-01\",\"2013-12-01\",\"2014-01-01\",\"2014-02-01\",\"2014-03-01\",\"2014-04-01\",\"2014-05-01\",\"2014-06-01\",\"2014-07-01\",\"2014-08-01\",\"2014-09-01\",\"2014-10-01\",\"2014-11-01\",\"2014-12-01\",\"2015-01-01\",\"2015-02-01\",\"2015-03-01\",\"2015-04-01\",\"2015-05-01\",\"2015-06-01\",\"2015-07-01\",\"2015-08-01\",\"2015-09-01\",\"2015-10-01\",\"2015-11-01\",\"2015-12-01\",\"2016-01-01\",\"2016-02-01\",\"2016-03-01\",\"2016-04-01\",\"2016-05-01\",\"2016-06-01\",\"2016-07-01\",\"2016-08-01\",\"2016-09-01\",\"2016-10-01\",\"2016-11-01\",\"2016-12-01\",\"2017-01-01\",\"2017-02-01\",\"2017-03-01\",\"2017-04-01\",\"2017-05-01\",\"2017-06-01\",\"2017-07-01\",\"2017-08-01\",\"2017-09-01\",\"2017-10-01\",\"2017-11-01\",\"2017-12-01\",\"2018-01-01\",\"2018-02-01\",\"2018-03-01\",\"2018-04-01\",\"2018-05-01\",\"2018-06-01\",\"2018-07-01\",\"2018-08-01\",\"2018-09-01\",\"2018-10-01\",\"2018-11-01\",\"2018-12-01\",\"2019-01-01\",\"2019-02-01\",\"2019-03-01\",\"2019-04-01\",\"2019-05-01\",\"2019-06-01\",\"2019-07-01\",\"2019-08-01\",\"2019-09-01\",\"2019-10-01\",\"2019-11-01\",\"2019-12-01\",\"2020-01-01\",\"2020-02-01\",\"2020-03-01\",\"2020-04-01\",\"2020-05-01\",\"2020-06-01\",\"2020-07-01\",\"2020-08-01\",\"2020-09-01\",\"2020-10-01\",\"2020-11-01\",\"2020-12-01\"],[40,72,48,50,100,85,68,67,49,56,69,55,55,35,60,85,68,61,49,47,52,53,92,64,49,51,57,53,65,32,47,68,43,74,49,51,39,53,53,51,58,51,41,45,51,56,64,31,66,59,52,53,61,45,52,45,45,63,57,57,56,46,56,54,42,34,48,54,38,57,73,49,53,56,49,55,64,59,19,41,47,47,67,62,41,71,88,72,44,48,32,34,60,54,67,53,63,66,69,62,55,42,37,43,51,48,48,42,47,59,42,57,60,47,41,46,58,74,70,53,66,46,65,69,68,53,73,71,70,65,67,66],[40,45,49,44,44,40,29,34,36,39,45,35,37,35,50,48,46,29,35,22,45,49,45,32,45,52,51,46,43,38,36,39,40,47,50,36,38,44,42,47,38,32,29,30,38,46,43,33,35,46,54,47,42,32,29,32,42,48,48,35,41,46,54,48,41,39,36,33,42,43,43,33,37,47,50,54,47,43,31,41,47,49,48,41,48,56,60,56,47,33,33,41,49,54,52,44,42,54,56,56,51,39,39,43,54,47,55,46,42,61,49,58,50,42,41,47,58,58,59,42,51,65,81,82,72,69,59,62,88,100,78,61],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132],[\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,4,5,6,7,8,9,10]],\"container\":\"<table class=\\\"cell-border stripe\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>date<\\/th>\\n      <th>workLifeBalance<\\/th>\\n      <th>wellBeing<\\/th>\\n      <th>elapsedTime<\\/th>\\n      <th>month<\\/th>\\n      <th>pandemic<\\/th>\\n      <th>elapsedTimeAfterPandemic<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pageLength\":5,\"autoWidth\":true,\"dom\":\"Bfrtip\",\"buttons\":[\"copy\"],\"scrollX\":true,\"selection\":\"multiple\",\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3,4,6,7]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"orderClasses\":false,\"orderCellsTop\":true,\"lengthMenu\":[5,10,25,50,100]}},\"evals\":[],\"jsHooks\":[]}\r\nTable 1: Final dataset used for testing hypothesis about impact of the COVID-19 pandemic on people’s interest in work-life balance and well-being.\r\n\r\nWe will model our data using common segmented regression models that have following general structure:\r\n\\[Y_{t} = β_{0} + β_{1}*time_{t} + β_{2}*intervention_{t} + β_{3}*time after intervention_{t} + e_{t}\\]\r\nGiven that we are dealing with correlated and truncated data, we will include in our models two specific terms – autocorrelation and truncation terms that will treat these specific characteristics of our data.\r\nNow let’s fit the data to the model and check what it tells us about the effect of pandemic on people’s search interest in work-life balance and well-being. We will use brms r package that enables making inferences about statistical models’ parameters within Bayesian inferential framework. Because of that, we also need to specify some additional parameters (e.g. chains, iter or warmup) of the Markov Chain Monte Carlo (MCMC) algorithm that will generate posterior samples of our models’ parameters.\r\nBayesian framework also enables us to specify priors for estimated parameter and through them include our domain knowledge in the analysis. The specified priors are important for both parameter estimation and hypothesis testing as they define our starting information state before we take into account our data. Here we will use rather wide, uninformative, and only mildly regularizing priors (it means that the results of the inference will be very close to the results of standard, frequentist parameter estimation/hypothesis testing).\r\n\r\n\r\n\r\n\r\n\r\n# uploading library for Bayesian statistical inference\r\nlibrary(brms)\r\n\r\n# specifying wide, uninformative, and only mildly regularizing priors for predictors in both models \r\npriors <- c(set_prior(\"normal(0,50)\", class = \"b\", coef = \"elapsedTime\"),\r\n            set_prior(\"normal(0,50)\", class = \"b\", coef = \"elapsedTimeAfterPandemic\"),\r\n            set_prior(\"normal(0,50)\", class = \"b\", coef = \"pandemic\"),\r\n            set_prior(\"normal(0,50)\", class = \"b\", coef = \"monthApr\"),\r\n            set_prior(\"normal(0,50)\", class = \"b\", coef = \"monthAug\"),\r\n            set_prior(\"normal(0,50)\", class = \"b\", coef = \"monthDec\"),\r\n            set_prior(\"normal(0,50)\", class = \"b\", coef = \"monthFeb\"),\r\n            set_prior(\"normal(0,50)\", class = \"b\", coef = \"monthJul\"),\r\n            set_prior(\"normal(0,50)\", class = \"b\", coef = \"monthJun\"),\r\n            set_prior(\"normal(0,50)\", class = \"b\", coef = \"monthMar\"),\r\n            set_prior(\"normal(0,50)\", class = \"b\", coef = \"monthMay\"),\r\n            set_prior(\"normal(0,50)\", class = \"b\", coef = \"monthNov\"),\r\n            set_prior(\"normal(0,50)\", class = \"b\", coef = \"monthOct\"),\r\n            set_prior(\"normal(0,50)\", class = \"b\", coef = \"monthSep\"))\r\n\r\n# defining the statistical model for work-life balance\r\nmodelWorkLifeBalance <- brms::brm(\r\n  workLifeBalance | trunc(lb = 0, ub = 100) ~ elapsedTime + pandemic + elapsedTimeAfterPandemic + month + ar(p = 1),\r\n  data = dfAll,\r\n  family = gaussian(),\r\n  prior = priors,\r\n  chains = 4,\r\n  iter = 3000,\r\n  warmup = 1000,\r\n  seed = 12345,\r\n  sample_prior = TRUE\r\n  )\r\n\r\n# defining the statistical model for well-being\r\nmodelWellBeing <- brms::brm(\r\n  wellBeing | trunc(lb = 0, ub = 100) ~ elapsedTime + pandemic + elapsedTimeAfterPandemic + month + ar(p = 1),\r\n  data = dfAll,\r\n  family = gaussian(),\r\n  prior = priors,\r\n  chains = 4,\r\n  iter = 3000,\r\n  warmup = 1000,\r\n  seed = 678910,\r\n  sample_prior = TRUE\r\n  )\r\n\r\n\r\n\r\n\r\nBefore making any inferences, we should make some sanity checks to be sure that the mechanics of the MCMC algorithm worked well and that we can use generated posterior samples for making inferences about our models’ parameters. There are many ways for doing that, but here we will use only visual check of the MCMC chains. We want plots of these chains look like hairy caterpillar which would indicate convergence of the underlying Markov chain to stationarity and convergence of Monte Carlo estimators to population quantities, respectively. As can be seen in Graph 1 and 2 below, in case of both models we can observe wanted characteristics of the MCMC chains described above. (For additional MCMC diagnostics procedures, see for example Bayesian Notes from Jeffrey B. Arnold.)\r\n\r\n\r\n# uploading library for plotting Bayesian models\r\nlibrary(bayesplot)\r\n\r\n# plotting the MCMC chains for the modelWorkLifeBalance \r\nbayesplot::mcmc_trace(\r\n  modelWorkLifeBalance,\r\n  facet_args = list(nrow = 6)\r\n  ) +\r\n  ggplot2::labs(\r\n    title = \"Plots of the MCMC chains used for estimation of the modelWorkLifeBalance's parameters\"\r\n    )\r\n\r\n\r\n\r\n\r\nGraph 1: Trace plots of Markov chains for individual parameters of the modelWorkLifeBalance.\r\n\r\n\r\n\r\n# plotting the MCMC chains for the modelWellBeing \r\nbayesplot::mcmc_trace(\r\n  modelWellBeing,\r\n  facet_args = list(nrow = 6)\r\n  ) +\r\n  ggplot2::labs(\r\n    title = \"Plots of the MCMC chains used for estimation of the modelWellBeing's parameters\"\r\n    )\r\n\r\n\r\n\r\n\r\nGraph 2: Trace plots of Markov chains for individual parameters of the modelWellBeing.\r\n\r\nIt is also important to check how well the models fit the data. We can use for this purpose posterior predictive checks that use specified number of sampled posterior values of models’ parameters and show how well the fitted models predict observed data. We can see in Graphs 3 and 4 that both models fit the observed data reasonably well.\r\n\r\n\r\n# investigating modelWorkLifeBalance fit\r\n\r\n# specifying the number of samples\r\nnsamples = 1000\r\n\r\nbrms::pp_check(\r\n  modelWorkLifeBalance, \r\n  nsamples = nsamples\r\n  ) + \r\n  ggplot2::labs(\r\n    title = stringr::str_glue(\"Posterior predictive checks for modelWorkLifeBalance (using {nsamples} samples)\")\r\n    )\r\n\r\n\r\n\r\n\r\nGraph 3: Posterior predictive checks comparing simulated/replicated data under the fitted modelWorkLifeBalance with the observed data.\r\n\r\n\r\n\r\n# investigating modelWellBeing fit\r\n\r\n# specifying the number of samples\r\nnsamples = 1000\r\n\r\nbrms::pp_check(\r\n  modelWellBeing, \r\n  nsamples = nsamples\r\n  ) + \r\n  ggplot2::labs(\r\n    title = stringr::str_glue(\"Posterior predictive checks for modelWellBeing (using {nsamples} samples)\")\r\n    )\r\n\r\n\r\n\r\n\r\nGraph 4: Posterior predictive checks comparing simulated/replicated data under the fitted modelWellBeing with the observed data.\r\n\r\nNow, after having sufficient confidence that - using terminology from the Richard McElreath’s book Statistical Rethinking - our “small worlds” can pretty accurately mimic the data coming from our real,“big world”, we can use our models’ parameters to learn something about our research questions. Our primary interest is in the coefficient value of the pandemic term in our models. It expresses how much and in what direction people’s search interest in work-life balance and well-being changed after the onset of pandemic.\r\nIn Graph 5 and 6 we can see posterior distributions of three selected parameters of our two models. In both cases the posterior distribution of the pandemic term is (predominantly or completely) on the right side of the zero value, which supports the claim about existence of the effect of pandemic on people’s increased search interest in work-life balance and well-being. As is apparent from the graphs, for well-being (Graph 6) this evidence is much stronger than for work-life balance (Graph 6), which corresponds to impression we might have when looking at the original Google Trends charts shown in Fig. 1 and 2.\r\n\r\n\r\n# uploading library for \r\nlibrary(tidybayes)\r\n\r\n# visualizing posterior distributions of selected parameters of the modelWorkLifeBalance\r\nmodelWorkLifeBalance %>%\r\n  tidybayes::gather_draws(\r\n    b_pandemic, b_elapsedTime, b_elapsedTimeAfterPandemic\r\n    ) %>%\r\n  dplyr::mutate(\r\n    .variable = factor(\r\n      .variable, \r\n      levels = c(\"b_pandemic\", \"b_elapsedTime\", \"b_elapsedTimeAfterPandemic\"), \r\n      ordered = TRUE\r\n      )\r\n    ) %>%\r\n  dplyr::rename(value = .value) %>%\r\n  ggplot2::ggplot(\r\n    aes(x = value)\r\n    ) +\r\n  ggplot2::geom_density(\r\n    fill = \"lightblue\"\r\n  ) +\r\n  ggplot2::facet_wrap(\r\n    ~.variable,\r\n    scales = \"free\",\r\n    nrow = 1\r\n    ) +\r\n  ggplot2::labs(\r\n    title = \"Posterior distributions of selected parameters of the modelWorkLifeBalance\"\r\n    )\r\n\r\n\r\n\r\n\r\nGraph 5: Visualization of the posterior distributions of selected parameters of the modelWorkLifeBalance.\r\n\r\n\r\n\r\n# visualizing posterior distributions of selected parameters of the modelWellBeing\r\nmodelWellBeing %>%\r\n  tidybayes::gather_draws(\r\n    b_pandemic, b_elapsedTime, b_elapsedTimeAfterPandemic\r\n    ) %>%\r\n  dplyr::mutate(\r\n    .variable = factor(\r\n      .variable, \r\n      levels = c(\"b_pandemic\", \"b_elapsedTime\", \"b_elapsedTimeAfterPandemic\"), \r\n      ordered = TRUE\r\n      )\r\n    ) %>%\r\n  dplyr::rename(value = .value) %>%\r\n  ggplot2::ggplot(\r\n    aes(x = value)\r\n    ) +\r\n  ggplot2::geom_density(\r\n    fill = \"lightblue\"\r\n  ) +\r\n  ggplot2::facet_wrap(\r\n    ~.variable,\r\n    scales = \"free\",\r\n    nrow = 1\r\n    ) +\r\n  ggplot2::labs(\r\n    title = \"Posterior distributions of selected parameters of the modelWellBeing\"\r\n    )\r\n\r\n\r\n\r\n\r\nGraph 5: Visualization of the posterior distributions of selected parameters of the modelWellBeing.\r\n\r\nTo generate more summary statistics about posterior distributions (and also some diagnostic information like Rhat or ESS), we can use summary() function.\r\n\r\n\r\n# generating a summary of the results for modelWorkLifeBalance \r\nsummary(modelWorkLifeBalance)\r\n\r\n\r\n Family: gaussian \r\n  Links: mu = identity; sigma = identity \r\nFormula: workLifeBalance | trunc(lb = 0, ub = 100) ~ elapsedTime + pandemic + elapsedTimeAfterPandemic + month + ar(p = 1) \r\n   Data: dfAll (Number of observations: 132) \r\nSamples: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;\r\n         total post-warmup samples = 8000\r\n\r\nCorrelation Structures:\r\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\r\nar[1]     0.21      0.09     0.03     0.39 1.00     6929     5764\r\n\r\nPopulation-Level Effects: \r\n                         Estimate Est.Error l-95% CI u-95% CI Rhat\r\nIntercept                   55.60      4.19    47.36    64.02 1.00\r\nelapsedTime                 -0.05      0.04    -0.13     0.02 1.00\r\npandemic                    14.03      9.96    -5.22    34.09 1.00\r\nelapsedTimeAfterPandemic     0.40      1.59    -2.68     3.54 1.00\r\nmonthFeb                     3.49      4.44    -5.38    12.19 1.00\r\nmonthMar                     4.51      4.92    -5.18    14.20 1.00\r\nmonthApr                     6.61      4.97    -3.26    16.50 1.00\r\nmonthMay                     8.82      4.97    -1.01    18.64 1.00\r\nmonthJun                    -2.82      4.98   -12.55     6.97 1.00\r\nmonthJul                    -7.31      5.05   -17.35     2.48 1.00\r\nmonthAug                    -2.45      5.00   -12.29     7.46 1.00\r\nmonthSep                    -2.20      5.02   -12.29     7.70 1.00\r\nmonthOct                     5.37      4.96    -4.41    15.24 1.00\r\nmonthNov                    12.36      4.95     2.83    22.13 1.00\r\nmonthDec                    -0.63      4.60    -9.53     8.49 1.00\r\n                         Bulk_ESS Tail_ESS\r\nIntercept                    2982     4366\r\nelapsedTime                  6859     5161\r\npandemic                     5274     5053\r\nelapsedTimeAfterPandemic     5271     5117\r\nmonthFeb                     3975     5259\r\nmonthMar                     3297     4998\r\nmonthApr                     3343     4860\r\nmonthMay                     3024     4502\r\nmonthJun                     3470     4861\r\nmonthJul                     3385     4434\r\nmonthAug                     3338     4583\r\nmonthSep                     3226     5026\r\nmonthOct                     3352     4802\r\nmonthNov                     3466     4560\r\nmonthDec                     3670     5099\r\n\r\nFamily Specific Parameters: \r\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\r\nsigma    11.55      0.78    10.16    13.23 1.00     6619     5559\r\n\r\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\r\nand Tail_ESS are effective sample size measures, and Rhat is the potential\r\nscale reduction factor on split chains (at convergence, Rhat = 1).\r\n\r\n\r\n\r\n\r\n# generating a summary of the results for modelWellBeing \r\nsummary(modelWellBeing)\r\n\r\n\r\n Family: gaussian \r\n  Links: mu = identity; sigma = identity \r\nFormula: wellBeing | trunc(lb = 0, ub = 100) ~ elapsedTime + pandemic + elapsedTimeAfterPandemic + month + ar(p = 1) \r\n   Data: dfAll (Number of observations: 132) \r\nSamples: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;\r\n         total post-warmup samples = 8000\r\n\r\nCorrelation Structures:\r\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\r\nar[1]     0.24      0.10     0.05     0.43 1.00     6384     5584\r\n\r\nPopulation-Level Effects: \r\n                         Estimate Est.Error l-95% CI u-95% CI Rhat\r\nIntercept                   34.80      1.75    31.35    38.33 1.00\r\nelapsedTime                  0.11      0.02     0.07     0.14 1.00\r\npandemic                    21.27      4.22    12.83    29.41 1.00\r\nelapsedTimeAfterPandemic     0.50      0.65    -0.78     1.83 1.00\r\nmonthFeb                     8.65      1.78     5.18    12.05 1.00\r\nmonthMar                    10.68      1.99     6.82    14.59 1.00\r\nmonthApr                     9.59      2.02     5.62    13.43 1.00\r\nmonthMay                     3.53      2.06    -0.51     7.61 1.00\r\nmonthJun                    -4.34      2.09    -8.51    -0.29 1.00\r\nmonthJul                    -8.03      2.06   -12.15    -4.03 1.00\r\nmonthAug                    -5.73      2.05    -9.75    -1.79 1.00\r\nmonthSep                     4.59      2.04     0.60     8.50 1.00\r\nmonthOct                     8.18      2.04     4.16    12.18 1.00\r\nmonthNov                     6.77      2.01     2.80    10.68 1.00\r\nmonthDec                    -4.92      1.86    -8.65    -1.36 1.00\r\n                         Bulk_ESS Tail_ESS\r\nIntercept                    2771     3898\r\nelapsedTime                  8342     5206\r\npandemic                     5207     4944\r\nelapsedTimeAfterPandemic     5357     5211\r\nmonthFeb                     3455     5359\r\nmonthMar                     3252     5178\r\nmonthApr                     3140     5199\r\nmonthMay                     2825     4470\r\nmonthJun                     3003     4295\r\nmonthJul                     2948     4784\r\nmonthAug                     2855     4792\r\nmonthSep                     2897     4940\r\nmonthOct                     2706     4463\r\nmonthNov                     3340     5019\r\nmonthDec                     3697     4293\r\n\r\nFamily Specific Parameters: \r\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\r\nsigma     4.64      0.31     4.09     5.30 1.00     7570     5941\r\n\r\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\r\nand Tail_ESS are effective sample size measures, and Rhat is the potential\r\nscale reduction factor on split chains (at convergence, Rhat = 1).\r\n\r\n\r\nGiven that for work-life balance model the posterior distribution of pandemic term crosses the zero value, it would be useful to know how strong is the evidence in the favor of hypothesis that pandemic term is larger than zero. For that purpose we can extract posterior samples and use them for calculation of the proportion of values that are larger/smaller than zero. The resulting proportions show that the vast majority of posterior distribution (approximately 93%) lies above zero.\r\n\r\n\r\n# extracting posterior samples\r\nsamples <- posterior_samples(modelWorkLifeBalance)\r\n\r\n# probability of b_pandemic coefficient being higher\r\nsum(samples$b_pandemic > 0) / nrow(samples)\r\n\r\n\r\n[1] 0.926125\r\n\r\n# probability of b_pandemic coefficient being lower than 0\r\nsum(samples$b_pandemic < 0) / nrow(samples)\r\n\r\n\r\n[1] 0.073875\r\n\r\n\r\nAnother option would be to compute Bayes factor that expresses degree to which available data favors our hypothesis in comparison with the null model corresponding to normal prior distribution with the parameters normal(0,50). We can see that Bayes factor (Evid.Ratio in the table below) has value around 12.5 which indicates strong evidence in favor of our hypothesis, in terms of Harold Jeffreys’ scale for interpretation of Bayes factors. Specifically it means that under the fitted model for well-being the hypothesis about pandemic term being higher than zero is 12.5 times more probable than under the null model. In other words, the data should shift our believe pretty strongly in direction of acceptance of the existence of pandemic’s positive effect on people’s search interest in work-life balance.\r\n\r\n\r\n# computing Bayes factor for hypothesis that pandemic term in the modelWorkLifeBalance is larger than zero  \r\nbrms::hypothesis(\r\n  modelWorkLifeBalance,\r\n  \"pandemic > 0\"\r\n  )\r\n\r\n\r\nHypothesis Tests for class b:\r\n      Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\r\n1 (pandemic) > 0    14.03      9.96    -2.21    30.54      12.54\r\n  Post.Prob Star\r\n1      0.93     \r\n---\r\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\r\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\r\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\r\nPosterior probabilities of point hypotheses assume equal prior probabilities.\r\n\r\n\r\n\r\n# plotting prior and posterior distribution for pandemic term in the modelWorkLifeBalance \r\nplot(\r\n  brms::hypothesis(\r\n    modelWorkLifeBalance,\r\n    \"pandemic > 0\"\r\n  )\r\n)\r\n\r\n\r\n\r\n\r\nGraph 6: Visualization of prior and posterior distribution of pandemic term in the modelWorkLifeBalance.\r\n\r\nBesides the major hypothesis we may be also interested in…\r\noverall trend across the last ten years,\r\ntrend after the onset of pandemic, and also\r\nseasonality of people’s search interest over the months within individual years.\r\nFor that purpose we might use, besides the summary statistics and graphs with posterior distributions depicted above, plots showing conditional effects for each of the predictors. From the plots in Graph 7 it is thus clear that in case of work-life balance searches, the overall trend across the last ten years is decreasing, after the onset of pandemic the trend is rather stagnating, and within individual years the search interest follows work & holiday seasonality (lower search interest during the holiday parts of the year - June, July, August and December - and higher during the rest of the year). In case of well-being searches, the seasonality part is similar, but the trends differ - both of them are increasing (see Graph 8).\r\n\r\n\r\n\r\n\r\n\r\n# uploading library for arranging multiple ggplots\r\nlibrary(ggpubr)\r\n\r\n# putting all graphs with conditional effects for modelWorkLifeBalance together  \r\nggpubr::ggarrange(\r\n  plotlist = figListWorkLifeBalance, \r\n  nrow = 4\r\n  ) %>%\r\n  ggpubr::annotate_figure(\r\n    top = text_grob(\"Conditional effects for each predictor in the modelWorkLifeBalance\")\r\n)\r\n\r\n\r\n\r\n\r\nGraph 7: Visualization of conditional effects of predictors from modelWorkLifeBalance. The predictors are conditioned on the mean in the case of continuous variables and reference category in the case of factors.\r\n\r\n\r\n\r\n\r\n\r\n\r\n# putting all graphs with conditional effects for modelWellBeing together  \r\nggpubr::ggarrange(\r\n  plotlist = figListWellBeing, \r\n  nrow = 4\r\n  ) %>% \r\n  ggpubr::annotate_figure(\r\n    top = text_grob(\"Conditional effects for each predictor in the modelWellBeing\")\r\n)\r\n\r\n\r\n\r\n\r\nGraph 8: Visualization of conditional effects of predictors from modelWellBeing. The predictors are conditioned on the mean in the case of continuous variables and reference category in the case of factors.\r\n\r\nIn conclusion, we can say that there is some evidence that the COVID-19 pandemic has prompted people to be more interested in topics related to work-life balance and well-being. I wish us all to be able to transform our increased interest in these topics into truly increased quality of our personal and professional lives. It would be a shame not to use that extra incentive many of us have now for making significant change in our lives.\r\nP.S. The whole script is available in Jupyter Notebook on GitHub.\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-12-31-segmentedregression/./workLifeBalanceGoogleTrends.png",
    "last_modified": "2021-01-19T19:49:25+01:00",
    "input_file": {},
    "preview_width": 1356,
    "preview_height": 680
  },
  {
    "path": "posts/2018-10-14-hr-analytika-a-odchodovost-zamstnanc/",
    "title": "HR analytika a odchodovost zaměstnanců",
    "description": "Které faktory přispívají k odchodovosti zaměstnanců a u kterých konkrétních zaměstnanců je zvýšené riziko, že firmu během několika příštích měsíců opustí? Na tyto otázky se čím dál tím více firem snaží odpovědět pomocí analýzy dat o svých vlastních zaměstnancích. V tomto článku se prostřednictvím analytického nástroje R a vizualizačního nástroje Shiny podíváme, jak může být tento druh HR analytického projektu pro firmy užitečný.",
    "author": [
      {
        "name": "Luděk Stehlík",
        "url": "https://www.linkedin.com/in/ludekstehlik/"
      }
    ],
    "date": "2018-10-14",
    "categories": [
      "employee turnover",
      "shiny dashboard",
      "r"
    ],
    "contents": "\r\n\r\nContents\r\nCo je to HR analytika?\r\nOdchodovost zaměstnanců a její prediktory\r\nNa důkazech založená pro-retenční opatření\r\n\r\nCo je to HR analytika?\r\nHR analytika ve své podstatě vychází ze známé zásady managementu, že co nelze měřit, nelze ani (efektivně) řídit a zlepšovat, a aplikuje tuto zásadu na lidské zdroje. V několika posledních letech potom k tomu navíc přidává nadstavbu v podobě pokročilejších analytických postupů, které mají větší potenciál přijít s hlubšími vhledy a s doporučeními s větším efektem. Ale ať už využíváte pouze základní reporting nebo nějakou pokročilejší analytiku, cíl je vždy stejný – snažit se s pomocí dat a jejich analýzy žádoucím způsobem ovlivnit jednotlivé HR procesy, které organizacím pomáhají dosahovat jejich strategických cílů. Názorně to ilustruje níže uvedené schéma zachycující mechanismus propojující HR procesy s (nejen) finančními výsledky organizace (Paauwe & Richardson, 1997).\r\n\r\nHR analytika pomáhá optimalizovat nastavení tohoto mechanismu tím, že umožňuje nalézat odpovědi na některé klíčové otázky, jako např.:\r\nKterými kanály se k nám dostávají ti nejlepší kandidáti?\r\nJaké charakteristiky od sebe odlišují úspěšné a neúspěšné kandidáty?\r\nKteré faktory přispívají k úspěšnému onboardingu?\r\nKterá „kápéíčka“ mají nejsilnější vazbu na finanční výsledky firmy?\r\nJaké tréninky vedou s nejvyšší pravděpodobností ke zlepšení pracovního výkonu?\r\nKteré intervence mají největší dopad na zaměstnanci pociťovaný well-being nebo work-life balance?\r\nCo u zaměstnanců zvyšuje, nebo naopak snižuje míru jejich angažovanosti?\r\nKde se v organizaci nachází izolovaná sila a úzká hrdla znemožňující efektivní komunikaci a spolupráci mezi jednotlivými zaměstnanci, týmy nebo i celými odděleními?\r\nKdo představuje skrytý talent, který je potřeba podchytit a dále rozvíjet?\r\nKde lze očekávat odpor v souvislosti s plánovanými změnami ve firmě a kdo naopak může být jejich ambasadorem a katalyzátorem?\r\nKteré faktory přispívají k odchodovosti zaměstnanců a u kterých konkrétních zaměstnanců je zvýšené riziko, že firmu během několika příštích měsíců opustí?\r\nOdchodovost zaměstnanců a její prediktory\r\nPrávě posledně jmenovaný způsob využití HR analytiky často představuje jeden z prvních druhů HR analytických projektů, kterými se ve firmách s HR analytikou začíná, a to z dobře pochopitelného důvodu. S nežádoucími odchody zaměstnanců jsou totiž spojené vysoké přímé i nepřímé náklady, takže i poměrně mírné snížení odchodovosti zaměstnanců může představovat značnou úsporu, kterou ocení management každé firmy. Naléhavost tohoto problému navíc ještě zvyšuje současná fáze ekonomického cyklu s rekordně nízkou mírou nezaměstnanosti, která v kombinaci s různými on-line platformami na zprostředkování práce motivuje mnoho lidí k hledání nového místa, kde, jak doufají, bude práce zajímavější, smysluplnější a lépe placená a kde kolegové budou sympatičtější a šéfové inspirativnější. Viz také graf níže, který na datech z USA názorně dokládá těsnost vztahu mezi mírou nezaměstnanosti a mírou dobrovolné odchodovosti zaměstnanců (r = -0,95, p < 0,001 ).\r\n\r\n\r\n\r\nVzhledem k palčivosti tohoto problému, který trápí nejednu firmu, není žádným velkým překvapením, že se tématu odchodovosti zaměstnanců věnovalo a stále věnuje velké množství různých studií. Takto např. na konci roku 2017 vyšla rozsáhlá meta-analýza od autorů Rubensteina, Eberlyové a Leeho, kteří syntetizovali výsledky více než 300 dílčích výzkumů týkajících se prediktorů odchodovosti. Můžeme se tak oprávněně ptát, co nového nám může přinést HR analytika zaměřená na odchodovost zaměstnanců realizovaná pouze v jediné organizaci. Nebylo vše podstatné k tomuto tématu již objeveno? (K této otázce viz např. tento inspirativní a trochu provokativní článek od Thomase Rasmussena.) Je pravda, že není příliš pravděpodobné, že při analýze vašich vlastních dat narazíte na nějaký naprosto nový faktor související s odchodovostí. Na druhou stranu je rovněž pravda, že každá organizace je v něčem jedinečná, takže některé z retenčních faktorů pro danou organizaci budou pravděpodobně více a jiné méně důležité. Tato informace o relativní důležitosti jednotlivých retenčních faktorů je potom klíčová při nastavování retenčního plánu a HR analytika může být při tomto velice nápomocná.\r\nNa důkazech založená pro-retenční opatření\r\nS pomocí tohoto dashboardu - vytvořeného prostřednictvím analytického nástroje R a vizualizačního nástroje Shiny a za využití ukázkových dat od společnosti IBM - si můžete sami vyzkoušet, jak užitečné by pro Vás mohly být výstupy z takového HR analytického projektu zaměřeného na odchodovost zaměstnanců. Dashboard obsahuje informace, které pomáhají (nejen) managementu zodpovědět řadu klíčových otázek, které stojí na počátku každého účinného plánu na retenci zaměstnanců, jako např.:\r\nKolik zaměstnanců nás ročně opouští?\r\nKteré skupiny zaměstnanců odcházejí nejčastěji?\r\nJaký je externí benchmark? Jsme na tom podobě jako konkurence v oboru?\r\nPředstavuje pro nás stávající úroveň odchodovosti závažný problém, a vyplatí se nám ho tedy řešit?\r\nZ jakých důvodů lidé obecně nejčastěji odcházejí ze zaměstnání?\r\nJaké faktory přispívají k odchodu specificky našich zaměstnanců?\r\nJaká pro-retenční opatření jsou obecně k dispozici?\r\nJaká pro-retenční opatření bychom měli zvolit vzhledem k pravděpodobným důvodům odchodů našich zaměstnanců?\r\nNa jaké skupiny zaměstnanců se především zaměřit z hlediska prevence jejich odchodovosti?\r\nU kterých konkrétních zaměstnanců existuje zvýšené riziko, že odejdou, a na jaké konkrétní retenční faktory se u nich zaměřit v rámci pravidelného stay interview?\r\nJak je z výše uvedeného výčtu otázek patrné, dashboard obsahuje informace, které při svém rozhodování mohou využít nejen HR manažeři, ale také HR business partneři nebo přímo team-leadeři a linioví manažeři jednotlivých týmů či oddělení. Kromě toho dashboard obsahuje také řadu technických detailů o použitém predikčním modelu a samotná data, které stojí v pozadí všech prezentovaných vizualizací a analýz. S jejich pomocí tak HR/Business analytik může např. hledat optimální způsob, jak nastavit skórovací algoritmus, aby se maximalizoval pozitivní efekt pro-retenčních opatření, nebo může v dostupných datech sám hledat nějaké další užitečné informace. Více viz již samotný dashboard, z něhož můžete níže vidět několik screenshotů.\r\nScreenshot části dashboardu, která obsahuje různé řezy odchodovostí zaměstnanců, a dává tak dobrý přehled o tom, které skupiny zaměstnanců jsou odchodovostí nejvíce ohrožené.\r\nScreenshot části dashboardu, která obsahuje informace o pravděpodobnosti odchodu jednotlivých zaměstnanců společně s dalšími informacemi, které mohou posloužit jako podklad pro individuální intervence s cílem předejít nežádoucím odchodům zaměstnanců. \r\nScreenshot části dashboardu, která obsahuje informace o výkonu/kvalitě statistického modelu použitého k identifikaci významných prediktorů odchodovosti zaměstnanců a k odhadu pravděpodobnosti odchodu jednotlivých zaměstnanců. \r\n\r\n\r\n\r\n",
    "preview": "posts/2018-10-14-hr-analytika-a-odchodovost-zamstnanc/./DSHB2.png",
    "last_modified": "2021-01-19T20:02:38+01:00",
    "input_file": "hr-analytika-a-odchodovost-zamstnanc.utf8.md",
    "preview_width": 1317,
    "preview_height": 926
  },
  {
    "path": "posts/2018-10-11-moneyball-v-hr-od-hr-analytiky-ke-sportovn-analytice-a-zpt/",
    "title": "Moneyball v HR - od HR analytiky ke sportovní analytice a zpět",
    "description": "Přes popularitu tématu HR analytiky mezi HR profesionály je stále relativně málo společností, které HR analytiku reálně a systematicky využívají. Jednou z možných příčin je to, že tradiční HR mnohdy postrádá analytický mindset a některé z kompetencí, které jsou klíčové pro úspěšnou realizaci HR analytických projektů. V takové situaci může být užitečné podívat se ve větším detailu na celkovou logiku i na konkrétní analytické kroky nějakého úspěšného příkladu využití HR analytiky k optimalizaci některého z HR procesů s pozitivním dopadem na obchodní výsledky společnosti. V tomto článku se tímto způsobem podíváme na známý příběh oaklandského baseballového týmu \"Áček\", jehož management poměrně radikálně - a podle všeho i úspěšně - přehodnotil svůj dosavadní přístup k výběru nových hráčů na základě výstupů statistické analýzy sabermetrických dat o herním chování hráčů. Využijeme při tom volně dostupný statistický software R a veřejně dostupnou databázi historických údajů o výsledcích v americké baseballové lize.",
    "author": [
      {
        "name": "Luděk Stehlík",
        "url": "https://www.linkedin.com/in/ludekstehlik/"
      }
    ],
    "date": "2018-10-11",
    "categories": [
      "structural equation modeling",
      "multivariate regression analysis",
      "correlation analysis",
      "r"
    ],
    "contents": "\r\n\r\nContents\r\n1. krok: Začít od konce aneb strategický rámec HR analytiky\r\n2. krok: Definice problému a kvantifikace cíle\r\n3. krok: Kladení otázek a měření\r\n4. krok: Kladení dalších otázek a další měření\r\n5. krok: Propojení dílčích vhledů aneb organizace jako stroj\r\n6. krok: Intervence\r\nOmezení HR analytiky\r\nZávěr\r\n\r\nHR analytika už dnes není ve světě HR žádnou horkou novinkou. Téměř všichni z oboru už o HR analytice něco slyšeli, něco o ní vědí a případně se jí už také pokouší ve svých organizacích v nějaké podobě zavádět. Zároveň většinou uznávají její důležitost při transformaci HR z podpůrné a administrativní funkce na funkci, která dokáže organizacím bezprostředně pomáhat dosahovat jejich strategických cílů. Navzdory tomuto všeobecnému povědomí o HR analytice a navzdory řadě úspěšně realizovaných HR analytických projektů (viz např. série článků od Davida Greena - článek 1, článek 2, článek 3, článek 4) překvapivě málo organizací HR analytiku reálně a systematicky využívá. Tento stav reflektují i výsledky výzkumu 2018 Human Capital Trends od společnosti Deloitte, ze kterých vyplývá, že organizace si většinou uvědomují strategickou důležitost výzvy, kterou představuje datifikace HR, zároveň se ale necítí být na čelení této výzvě příliš dobře připraveny. Už nějakou dobu platí, že když už se v organizaci s HR daty nějak pracuje, tak je to většinou pouze na úrovni nějakého základního reportingu vybraných HR metrik a KPIs typu náklady na nábor, délka období neobsazenosti volné pracovní pozice, míra ne/dobrovolné odchodovosti zaměstnanců, počet zaměstnanců na jednoho HR business partnera apod. Slabinou tohoto přístupu je, že takto sledované metriky jsou často relevantní pouze pro monitorování a řízení efektivnosti HR coby nákladového střediska, ale již méně pro dosahování strategických cílů organizace. Spíše výjimečně se potom v tomto kontextu využívají nějaké pokročilejší analytiky, které obecně mají větší potenciál přicházet s doporučeními s přímým dopadem na schopnost organizací dosahovat svých strategických cílů.\r\nVýsledky výzkumu provedeného společnostmi MIT Sloan Management Review a SAS naznačují, že tento nevyužitý potenciál HR analytiky má dvě hlavní příčiny. První z nich je to, že tradiční HR mnohdy postrádá analytický mindset a některé z kompetencí, které jsou klíčové pro úspěšnou realizaci HR analytických projektů (přehled těchto kompetencí a důsledků jejich absence či nedostatečné úrovně viz např. tento článek od Mortena Kamp Andersena). Ve stejném duchu Josh Bersin ve své zprávě HR Technology Disruptions for 2018 konstatuje, že zvládnutí základních analytických dovedností patří mezi nejdůležitější prediktory efektivní implementace HR analytiky v organizacích: “Equip all HR staff with basic data literacy skills. All HR practitioners should know basic statistical concepts, where to find data, how to slice and dice it, how to read a dashboard, and how to bring data and analytics to bear on business issues. Our research reveals that such basic skills are among the most important predictors of high-performing people analytics.”\r\nDruhou hlavní příčinou je potom to, že HR analytické projekty nebývají ukotveny v rámci nějaké širší strategie, jak data systematicky využívat při řízení lidských zdrojů, navíc způsobem, který by byl sladěný se strategickými cíli společnosti. Zde platí praxí osvědčená pravda projektového managementu, že při implementaci projektů je potřeba vždy začínat od konce. V kontextu HR analytických projektů to tedy znamená začínat nikoli od dat, ale od toho, k čemu mají být HR analytické výstupy použity. A očekávání managementu je, že HR analytika bude v posledku hlavně pomáhat zlepšovat obchodní výsledky společnosti. Názorně to ilustruje níže uvedené schéma (převzaté z článku Maxe Blumberga), které zachycuje předpokládaný kauzální řetězec spojující HR procesy s obchodními výsledky. Úkolem HR analytiky je potom s pomocí dat a analytických nástrojů tyto dvě oblasti propojit a zjistit, jak optimalizací prvního zajistit zlepšení toho druhého.\r\n\r\nŘadě organizací by v tomto ohledu mohl být inspirací známý příběh oaklandského baseballového týmu „Áček“, který se stal předlohou pro knihu Moneyball a z ní vycházející stejnojmenný film. Právě tento příběh jako jeden z prvních ukázal a mezi širokou veřejností zpopularizoval možnosti využití statistické analýzy ve světě sportu a potažmo také v rámci řízení lidských zdrojů. Díky radikální změně dosavadního přístupu k výběru nových hráčů, který se začal více opírat o výstupy statistické analýzy sabermetrických dat o herním chování hráčů, dokázal management oaklandského baseballového týmu „Áček“ přijímat rozhodnutí, která z jednoho z nejchudších týmů americké baseballové ligy učinila jeden z nejúspěšnějších týmů soutěže (měřeno počtem vítězství v základní části soutěže a počtem postupů do play-off). Abychom mohli tento příběh plně vytěžit coby inspiraci, jak analyzovat svá vlastní zaměstnanecká data, bude užitečné, když se na jednotlivé analytické kroky, které stály v pozadí úspěchu oklandských “Áček”, podíváme trochu podrobněji. A učiníme tak za využití volně dostupného statistického softwaru R a veřejně dostupné databáze historických údajů o výsledcích v americké baseballové lize.\r\n1. krok: Začít od konce aneb strategický rámec HR analytiky\r\nJak bylo uvedeno výše, často podceňovaným krokem při zavádění HR analytiky do firem a organizací je zasazení HR analytiky do nějakého širšího strategického rámce, ze kterého by jasně vyplývalo, čemu má vlastně HR analytika sloužit. HR analytika je pouze nástroj, konkrétně nástroj na zodpovídání otázek, resp. na testování různých hypotéz. To, zda bude tento nástroj užitečný, závisí na tom, zda si dokážeme klást ty správné otázky. To je přitom z velké části dáno tím, zda si jsme vědomi, jaké jsou strategické cíle naší organizace. Jen ve světle těchto cílů dává smysl klást si nějaké otázky, sbírat a analyzovat nějaká data za účelem nalezení odpovědí na položené otázky a posléze činit nějaká konkrétní rozhodnutí na základě nalezených odpovědí. V případě oaklandských „Áček“ byl cíl jasný – kvalifikovat se do play-off.\r\n2. krok: Definice problému a kvantifikace cíle\r\nPaul DePodesta, kterého generální manažer oaklandských „Áček“ Billy Beane přijal do týmu jako statistického analytika, redukoval tento cíl na celkem jednoduchý matematický problém: Kolik zápasů musí tým vyhrát, aby se kvalifikoval do play-off? K zodpovězení této otázky DePodesta potřeboval historická data o počtu vítězství jednotlivých týmů v minulých sezónách a o tom, zda se jim podařilo postoupit do play-off, či nikoli.\r\n\r\n\r\n# Nacteme si knihovnu, která nám umožní si nacíst a predpripravit data k analýze a také je i vizualizovat.  \r\nlibrary(tidyverse)\r\n\r\n# Nacteme si naše data..\r\nbaseball <- read_csv(\"baseball.csv\")\r\n\r\n# Pro získání lepší predstavy o nich se podívejme na jejich prvních deset rádku..\r\nhead(baseball, 10)\r\n\r\n\r\n# A tibble: 10 x 15\r\n   Team  League  Year    RS    RA     W   OBP   SLG    BA Playoffs\r\n   <chr> <chr>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>\r\n 1 ARI   NL      2012   734   688    81 0.328 0.418 0.259        0\r\n 2 ATL   NL      2012   700   600    94 0.32  0.389 0.247        1\r\n 3 BAL   AL      2012   712   705    93 0.311 0.417 0.247        1\r\n 4 BOS   AL      2012   734   806    69 0.315 0.415 0.26         0\r\n 5 CHC   NL      2012   613   759    61 0.302 0.378 0.24         0\r\n 6 CHW   AL      2012   748   676    85 0.318 0.422 0.255        0\r\n 7 CIN   NL      2012   669   588    97 0.315 0.411 0.251        1\r\n 8 CLE   AL      2012   667   845    68 0.324 0.381 0.251        0\r\n 9 COL   NL      2012   758   890    64 0.33  0.436 0.274        0\r\n10 DET   AL      2012   726   670    88 0.335 0.422 0.268        1\r\n# ... with 5 more variables: RankSeason <dbl>, RankPlayoffs <dbl>,\r\n#   G <dbl>, OOBP <dbl>, OSLG <dbl>\r\n\r\n# Pro následující analýzy si potom vytvorme podmnožinu dat, která meli k dispozici v Oaklandu v roce 2002, kdy se dej Moneyballu prevážne odehrává.á.\r\nmoneyball <- baseball %>%\r\n  filter(Year < 2002)\r\n\r\n\r\n\r\nPodíváme-li se na data mezi lety 1996–2001, tj. na data z relativně nedávné minulosti (vztaženo k roku 2002, kdy se děj Moneyballu převážně odehrává), z grafického vyjádření vztahu mezi počtem vítězství v základní částí soutěže a postupem do play-off je dobře patrné, že čím více zápasů tým vyhraje v základní soutěži, tím větší je šance, že se také dostane do play-off.\r\n\r\n\r\n# Vytvorme si graf zachycující vztah mezi poctem vítezství v základní cásti souteže a postupem do play-offf\r\nmoneyball %>%\r\n  filter(Year < 2002 & Year > 1995) %>%\r\n  select (W, Playoffs) %>%\r\n  mutate(rnd = runif(176,0,1)) %>%\r\n  ggplot(aes(x = W, y = rnd, color = as.factor(Playoffs)))+\r\n  geom_point(size = 2)+\r\n  scale_x_continuous(limits=c(50,120), breaks = seq(50,120,5))+\r\n  scale_color_manual(values = c(\"#9e9e9e\", \"#ff1919\"), labels = c(\"Tým nepostoupil do play-off\",\"Tým postoupil do play-off\"))+\r\n  ggtitle(\"Postupy týmu do play-off mezi lety 1996-2001\")+\r\n  ylab(\"\")+\r\n  xlab(\"Pocet vítezství v základní cásti souteže\")++\r\n  theme(legend.position = \"bottom\",\r\n        axis.ticks.y = element_blank(),\r\n        axis.text.y = element_blank(),\r\n        axis.text.x = element_text(size=11),\r\n        axis.title.x = element_text(size=11),\r\n        legend.text = element_text(size=11),\r\n        legend.title = element_blank())\r\n\r\n\r\n\r\n\r\nS daty, která máme k dispozici, máme tu výhodu, že můžeme vztah mezi počtem vítězství v základní části soutěže a šancí na postup do play-off přesně kvantifikovat. Provedeme-li podrobnější analýzu našich dat, ukáže se, že velkou (přibližně 95%) šanci na postup do play-off má tým tehdy, když v základní části vyhraje minimálně 95 zápasů. Těchto 95 vítězství představuje dobře definovaný a kvantifikovaný cíl, kterého by se oaklandská „Áčka“ měla snažit dosáhnout.\r\n\r\n\r\n# Vyfiltrujme si opet data mezi lety 1996-2001. \r\nmoneyball2 <- moneyball %>%\r\n  filter(Year < 2002 & Year > 1995)\r\n\r\n# Vytvorme si seznam nekolika ruzných hodnot poctu vítezství v základní cásti souteže..\r\npocet_vitezstvi <- seq(60,115,5)\r\nucast_v_playoff <- vector(mode=\"numeric\", length=length(pocet_vitezstvi))\r\nplayoff_data <- data.frame(pocet_vitezstvi = pocet_vitezstvi, ucast_v_playoff = ucast_v_playoff)\r\n\r\n# Vypocteme si, jaká je pravdepodobnost postupu do play-off pri ruzném poctu vítezství v základní cásti souteže..\r\nfor(i in 1:nrow(playoff_data)){\r\n playoff_data$ucast_v_playoff[i] <- length(moneyball2$W[moneyball2$W >= playoff_data$pocet_vitezstvi[i] & moneyball2$Playoffs == 1])/length(moneyball2$W[moneyball2$W >= playoff_data$pocet_vitezstvi[i]]) \r\n}\r\n\r\n# A nyní si vztah mezi poctem vyhraných zápasu v základní cásti souteže a pravdepodobností úcasti v play-off vizualizujme..\r\nggplot(playoff_data, aes(x = pocet_vitezstvi, y = ucast_v_playoff))+\r\n  geom_point(size = 2)+\r\n  geom_line()+\r\n  ggtitle(\"Souvislost mezi poctem výher v základní cásti souteže a\\npravdepodobností postupu týmu do play-off (1996-2001)\")++\r\n  ylab(\"Pravdepodobnost postupu týmu do play-off\")+\r\n  xlab(\"Pocet vítezství v základní cásti souteže\")++\r\n  scale_x_continuous(limits=c(60,115), breaks = seq(60,115,5))+\r\n  scale_y_continuous(limits=c(0,1), breaks = seq(0,1,0.1))+\r\n  theme(axis.text = element_text(size=11),\r\n        axis.title = element_text(size=11))\r\n\r\n\r\n\r\n\r\n3. krok: Kladení otázek a měření\r\nS takto definovaným a kvantifikovaným cílem si potom můžeme klást dalších otázky, na které když si dokážeme odpovědět, zvýšíme tím naše šance na to, že tohoto cíle dosáhneme. V případě oaklandských „Áček“ se můžeme ptát, díky čemu tým dosahuje v zápasech vítězství? Celkem zjevná odpověď zní, že díky tomu, že dokáže získat více bodů než jeho soupeři. Otázkou ale je, přesně o kolik bodů navíc musí tým získat, aby v základní části soutěže dosáhl na minimálně 95 vítězství. K zodpovězení této otázky opět potřebujeme historická data (údaje o vyhraných a prohraných bodech) a relativně jednoduchý statistický model zvaný lineární regrese, pomocí kterého můžeme popsat vztah mezi počtem vyhraných zápasů v základní části soutěže a rozdílem mezi vyhranými a prohranými body. Z níže uvedeného grafu je zřejmé, že mezi těmito dvěma proměnnými je velice těsný vztah a že spolu velice silně korelují.\r\n\r\n\r\n# Vypocteme si rozdíl mezi vyhranými a prohranými body\r\nmoneyball <- moneyball %>%\r\n  mutate(RD = RS - RA)\r\n\r\n# Graficky si znázorneme vztah mezi poctem vyhraných zápasu v základní cásti souteže a rozdílem mezi vyhranými a prohranými bodyy\r\nlibrary(ggpubr)\r\nggplot(moneyball, aes(x = RD , y = W))+\r\n  geom_point(alpha = 0.5, size = 2)+\r\n  geom_smooth(method = \"lm\", se = FALSE)+\r\n  ggtitle(\"Vztah mezi poctem vítezství v základní cásti souteže a\\nrozdílem mezi vyhranými a prohranými body\")++\r\n  xlab(\"Rozdíl mezi poctem vyhraných a prohraných bodu\")+\r\n  ylab(\"Pocet vítezství\")+\r\n  theme(axis.title = element_text(size = 11),\r\n        axis.text = element_text(size = 11))+\r\n  scale_x_continuous(limits = c(-350,350), breaks = seq(-350,350,50))+\r\n  scale_y_continuous(limits = c(40, 120), breaks = seq(40,120,10))+\r\n  stat_cor(method = \"pearson\", label.x = 275, label.y = 45)\r\n\r\n\r\n\r\n\r\nPři použití modelu lineární regrese můžeme vztah mezi těmito dvěma proměnnými popsat trochu podrobněji.\r\n\r\n\r\n# Regresní analýza vztahu mezi mezi poctem vyhraných zápasu v základní cásti souteže a rozdílem mezi vyhranými a prohranými body  \r\nreg_model1 <- glm(W ~ RD, data = moneyball, family = \"gaussian\")\r\nsummary(reg_model1)\r\n\r\n\r\n\r\nCall:\r\nglm(formula = W ~ RD, family = \"gaussian\", data = moneyball)\r\n\r\nDeviance Residuals: \r\n     Min        1Q    Median        3Q       Max  \r\n-14.2662   -2.6509    0.1234    2.9364   11.6570  \r\n\r\nCoefficients:\r\n             Estimate Std. Error t value Pr(>|t|)    \r\n(Intercept) 80.881375   0.131157  616.67   <2e-16 ***\r\nRD           0.105766   0.001297   81.55   <2e-16 ***\r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\n(Dispersion parameter for gaussian family taken to be 15.51641)\r\n\r\n    Null deviance: 117164  on 901  degrees of freedom\r\nResidual deviance:  13965  on 900  degrees of freedom\r\nAIC: 5037\r\n\r\nNumber of Fisher Scoring iterations: 2\r\n\r\nVýsledná regresní rovnice nám říká, že očekávaný počet vítězství = 80.88 + 0.106 x Rozdílový skór. Tzn., že při vyrovnaném poměru vyhraných a prohraných bodů můžeme očekávat, že tým vyhraje přibližně 80 zápasů za sezónu, a že když se rozdílové skóre navýší o deset bodů, můžeme očekávat, že tým vyhraje v průměru o jeden zápas za sezónu navíc. Klíčové je ale pro nás to, že s pomocí této rovnice a s trochou algebry si můžeme jednoduše vypočítat, že k dosažení minimálně 95 vítězství za sezónu potřebuje tým vyhrát přibližně o 133 bodů více, než kolik jich se soupeři prohraje ((95 - 80.88) / 0.106).\r\n4. krok: Kladení dalších otázek a další měření\r\nTímto zjištěním se náš cíl opět trochu více specifikuje a vyvolává další otázky. Otázka, která se téměř sama nabízí, se týká charakteristik hráčů, které nejlépe předpovídají počet vyhraných a prohraných bodů, a tím tedy také pravděpodobnost postupu týmu do play-off. DePodesta na základě svých analýz zjistil, že počet vyhraných bodů nejtěsněji souvisí s procentem případů, kdy se hráč dostane na metu (tzv. On-Base Percentage - OBP), a to, jak daleko se hráč dostane při svém odpalu (tzv. Slugging Percentage - SLG). Analogické statistiky pro týmy soupeřů (OOBP a OSLG) potom stejně dobře předpovídají počet prohraných bodů. Když vztah mezi těmito proměnnými popíšeme opět pomocí modelu lineární regrese, můžeme se s jeho pomocí pokusit předpovědět, jak si tým povede příští sezónu. Taková předpověď by přitom mohla být potenciálně velice užitečná, protože na jejím základě bychom případně mohli upravit některá svá rozhodnutí o koupi nebo prodeji vybraných hráčů. Pojďme tuto předpověď vytvořit pro tým oaklandských „Áček“ pro sezónu 2002 na základě dat z let 1962-2001. Z předchozí analýzy již víme, že…\r\nPočet vítězství = 80.88 + 0.106 x (Počet vyhraných bodů - Počet prohraných bodů).\r\nNyní potřebujeme určit, jaký bude pravděpodobný počet vyhraných a prohraných bodů. Pomůžeme si opět regresní analýzou.\r\n\r\n\r\n# Regresní analýza vztahu mezi mezi poctem vyhraných bodu v základní cásti souteže a dvema vybranými hrácskými/týmovými statistikami  \r\nregModel2 = lm(RS ~ OBP + SLG, data=moneyball)\r\nsummary(regModel2)\r\n\r\n\r\n\r\nCall:\r\nlm(formula = RS ~ OBP + SLG, data = moneyball)\r\n\r\nResiduals:\r\n    Min      1Q  Median      3Q     Max \r\n-70.838 -17.174  -1.108  16.770  90.036 \r\n\r\nCoefficients:\r\n            Estimate Std. Error t value Pr(>|t|)    \r\n(Intercept)  -804.63      18.92  -42.53   <2e-16 ***\r\nOBP          2737.77      90.68   30.19   <2e-16 ***\r\nSLG          1584.91      42.16   37.60   <2e-16 ***\r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 24.79 on 899 degrees of freedom\r\nMultiple R-squared:  0.9296,    Adjusted R-squared:  0.9294 \r\nF-statistic:  5934 on 2 and 899 DF,  p-value: < 2.2e-16\r\n\r\n# Regresní analýza vztahu mezi mezi poctem prohraných bodu v základní cásti souteže a dvema vybranými hrácskými/týmovými statistikami  \r\nregModel3 = lm(RA ~ OOBP + OSLG, data=moneyball)\r\nsummary(regModel3)\r\n\r\n\r\n\r\nCall:\r\nlm(formula = RA ~ OOBP + OSLG, data = moneyball)\r\n\r\nResiduals:\r\n    Min      1Q  Median      3Q     Max \r\n-82.397 -15.178  -0.129  17.679  60.955 \r\n\r\nCoefficients:\r\n            Estimate Std. Error t value Pr(>|t|)    \r\n(Intercept)  -837.38      60.26 -13.897  < 2e-16 ***\r\nOOBP         2913.60     291.97   9.979 4.46e-16 ***\r\nOSLG         1514.29     175.43   8.632 2.55e-13 ***\r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 25.67 on 87 degrees of freedom\r\n  (812 observations deleted due to missingness)\r\nMultiple R-squared:  0.9073,    Adjusted R-squared:  0.9052 \r\nF-statistic: 425.8 on 2 and 87 DF,  p-value: < 2.2e-16\r\n\r\nS pomocí regresní analýzy jsme zjistili, že…\r\nPočet vyhraných bodů = -804.63 + 2737.77 x OBP + 1584.91 x SLGPočet prohraných bodů = -837.38 + 2913.60 x OOBP + 1514.29 x OSLG.\r\nSe znalostí hráčských/týmových statistik oaklandských „Áček“ za rok 2001 se nyní můžeme pokusit předpovědět nejdříve počet vyhraných a prohraných bodů a potom také předpokládaný počet vítězství v základní části soutěže. Při formulování této předpovědi vycházíme z předpokladu, že se složení týmu v průběhu sezóny 2002 nebude (např. z důvodu zranění hráčů) příliš lišit od jeho složení v roce 2001.\r\n\r\n\r\n# Hrácské/týmové statistiky oaklandských „Ácek“ za rok 200101\r\nOBP_OAK <- moneyball$OBP[which(moneyball$Team==\"OAK\" & moneyball$Year == 2001)]\r\nSLG_OAK <- moneyball$SLG[which(moneyball$Team==\"OAK\" & moneyball$Year == 2001)]\r\nOOBP_OAK <- moneyball$OOBP[which(moneyball$Team==\"OAK\" & moneyball$Year == 2001)]\r\nOSLG_OAK <- moneyball$OSLG[which(moneyball$Team==\"OAK\" & moneyball$Year == 2001)]\r\n\r\n# Pravdepodobné hodnoty vybraných statistik oaklandských \"Ácek\" pro rok 2002 vypocítané s pomocí odhadnutých regresních modelu\r\npocet_vyhranych_bodu_pred <- round(-804.63 + 2737.77*OBP_OAK + 1584.91*SLG_OAK)\r\npocet_prohranych_bodu_pred <- round(-837.38 + 2913.60*OOBP_OAK + 1514.29*OSLG_OAK)\r\npocet_vitezstvi_pred <- round(80.88 + 0.106 * (pocet_vyhranych_bodu_pred - pocet_prohranych_bodu_pred), 0)\r\n\r\n# Skutecné hodnoty vybraných statistik oaklandských \"Ácek\" pro rok 2002\r\npocet_vyhranych_bodu_real <- baseball$RS[which(baseball$Team==\"OAK\" & baseball$Year == 2002)] \r\npocet_prohranych_bodu_real <- baseball$RA[which(baseball$Team==\"OAK\" & baseball$Year == 2002)] \r\npocet_vitezstvi_real <- baseball$W[which(baseball$Team==\"OAK\" & baseball$Year == 2002)]\r\n\r\n# Tabulka porovnávající statistické predpovedi se skutecností \r\npred <- c(pocet_vyhranych_bodu_pred, pocet_prohranych_bodu_pred, pocet_vitezstvi_pred)\r\nreal <- c(pocet_vyhranych_bodu_real, pocet_prohranych_bodu_real, pocet_vitezstvi_real)\r\ntable <- data.frame(\"Predpoved\" = pred, \"Skutecnost\" = real)\r\nrow.names(table) <- c(\"Vyhrané body\", \"Prohrané body\", \"Pocet vítezství\")\r\ntable\r\n\r\n\r\n                Predpoved Skutecnost\r\nVyhrané body          836        800\r\nProhrané body         635        654\r\nPocet vítezství       102        103\r\n\r\nPorovnání našich předpovědí s reálnými výsledky za sezónu 2002 ukazuje, že se nám podařilo velice přesně předpovědět výsledky v nadcházející ligové sezóně, a významně tak snížit míru naší nejistoty při jejím plánování.\r\n5. krok: Propojení dílčích vhledů aneb organizace jako stroj\r\nMatt Dancho ve své metodice k datově-analytickým projektům doporučuje, abychom se při snaze o pochopení obchodního problému organizace na danou organizaci dívali jako na druh stroje, který má určité vstupy, procesy a výstupy. Tuto metaforu stroje můžeme nyní využít k tomu, abychom všechny výše uvedené dílčí vhledy spojili do jednotného rámce. V něm budou mít oaklandská “Áčka” podobu jednoduchého stroje na výrobu postupů do play-off - viz obrázek níže.\r\n\r\nZe schématu je dobře patrné, jak tento stroj funguje: Jeho výstupy jsou postupy do play-off, kterých dosahuje tak, že se snaží vyhrát více zápasů, resp. získat více bodů než soupeřící týmy; k tomu využívá vstupy v podobě schopnosti hráčů hrát dobře na pálce a v poli; vstupem ovlivňujícím chod stroje jsou rovněž obdobné schopnosti hráčů soupeřících týmů. Jedná se samozřejmě o velmi zjednodušený kauzální model fungování týmu oakladnských “Áček”, ale jak konstatuje slavný statistický aforismus, modely jsou vždy nepřesné, ale některé z nich jsou užitečné.\r\nJakkoli naše modely fungování organizace budou vždy neúplné, je důležité ověřit, zda tyto modely i přes svou omezenost v dostatečné míře odrážejí realitu tak, jak nám ji zprostředkovávají dostupná data. Za tímto účelem můžeme použít statistickou metodu strukturálního modelování, která umožňuje formalizovat naše představy o vzájemných vztazích mezi několika různými proměnnými a zhodnotit míru souladu těchto našich představ s dostupnými daty. Teprve po takovém zhodnocení věrohodnosti modelu je rozumné na něm zakládat svá další rozhodnutí. Pojďme tedy tuto metodu použít rovněž na náš nově vytvořený model fungování týmu oaklandských “Áček” a ověřit míru jeho věrohodnosti.\r\n\r\n\r\n# Data, která budeme potrebovat pro overení verohodnosti našeho modelu fungování oaklandských \"Ácek\"  \r\nsem_data <- moneyball %>%\r\n  filter(Year < 2002 & Year > 1995) %>%\r\n  select(RS, RA, RD, W, Playoffs, OBP, SLG, OOBP, OSLG)\r\n\r\n# Definice modelu, která je v souladu s výše uvedeným schématemm\r\nlibrary(lavaan)\r\noak_model <- '\r\n     Playoffs ~ W\r\n     W ~ RS + RA\r\n     RA ~ OOBP + OSLG\r\n     RS ~ OBP + SLG \r\n'\r\n# Odhad parametru modelu\r\nfit_oak_model <- sem(oak_model, data = sem_data, missing = \"pairwise\", estimator = \"WLSMV\", ordered = \"Playoffs\")\r\nsummary(fit_oak_model, standardized = T, fit.measures = T, rsq = T)\r\n\r\n\r\nlavaan 0.6-5 ended normally after 257 iterations\r\n\r\n  Estimator                                       DWLS\r\n  Optimization method                           NLMINB\r\n  Number of free parameters                         14\r\n                                                      \r\n                                                  Used       Total\r\n  Number of observations                            90         176\r\n  Number of missing patterns                         1            \r\n                                                                  \r\nModel Test User Model:\r\n                                              Standard      Robust\r\n  Test Statistic                                 3.724       7.301\r\n  Degrees of freedom                                15          15\r\n  P-value (Chi-square)                           0.999       0.949\r\n  Scaling correction factor                                  1.397\r\n  Shift parameter                                            4.635\r\n    for the simple second-order correction \r\n\r\nModel Test Baseline Model:\r\n\r\n  Test statistic                                 1.511       2.808\r\n  Degrees of freedom                                 6           6\r\n  P-value                                        0.959       0.833\r\n  Scaling correction factor                                  1.406\r\n\r\nUser Model versus Baseline Model:\r\n\r\n  Comparative Fit Index (CFI)                    1.000       1.000\r\n  Tucker-Lewis Index (TLI)                      -0.005       0.035\r\n                                                                  \r\n  Robust Comparative Fit Index (CFI)                            NA\r\n  Robust Tucker-Lewis Index (TLI)                               NA\r\n\r\nRoot Mean Square Error of Approximation:\r\n\r\n  RMSEA                                          0.000       0.000\r\n  90 Percent confidence interval - lower         0.000       0.000\r\n  90 Percent confidence interval - upper         0.000       0.008\r\n  P-value RMSEA <= 0.05                          1.000       0.981\r\n                                                                  \r\n  Robust RMSEA                                                  NA\r\n  90 Percent confidence interval - lower                     0.000\r\n  90 Percent confidence interval - upper                        NA\r\n\r\nStandardized Root Mean Square Residual:\r\n\r\n  SRMR                                           0.185       0.185\r\n\r\nParameter Estimates:\r\n\r\n  Information                                 Expected\r\n  Information saturated (h1) model        Unstructured\r\n  Standard errors                           Robust.sem\r\n\r\nRegressions:\r\n                   Estimate   Std.Err  z-value  P(>|z|)   Std.lv \r\n  Playoffs ~                                                     \r\n    W                  0.241    0.115    2.095    0.036     0.241\r\n  W ~                                                            \r\n    RS                 0.099    0.006   16.342    0.000     0.099\r\n    RA                -0.103    0.008  -13.465    0.000    -0.103\r\n  RA ~                                                           \r\n    OOBP            3046.113  366.056    8.321    0.000  3046.113\r\n    OSLG            1465.117  206.759    7.086    0.000  1465.117\r\n  RS ~                                                           \r\n    OBP             3575.472  259.145   13.797    0.000  3575.472\r\n    SLG             1397.378  144.203    9.690    0.000  1397.378\r\n  Std.all\r\n         \r\n    0.994\r\n         \r\n    0.694\r\n   -0.738\r\n         \r\n    0.559\r\n    0.448\r\n         \r\n    0.603\r\n    0.422\r\n\r\nIntercepts:\r\n                   Estimate   Std.Err  z-value  P(>|z|)   Std.lv \r\n   .Playoffs           0.000                                0.000\r\n   .W                 96.559    8.355   11.556    0.000    96.559\r\n   .RA              -808.808  116.566   -6.939    0.000  -808.808\r\n   .RS             -1041.496   73.943  -14.085    0.000 -1041.496\r\n  Std.all\r\n    0.000\r\n    8.256\r\n   -9.635\r\n  -12.759\r\n\r\nThresholds:\r\n                   Estimate   Std.Err  z-value  P(>|z|)   Std.lv \r\n    Playoffs|t1       23.191   10.204    2.273    0.023    23.191\r\n  Std.all\r\n    8.179\r\n\r\nVariances:\r\n                   Estimate   Std.Err  z-value  P(>|z|)   Std.lv \r\n   .Playoffs           0.095                                0.095\r\n   .W                  3.968    3.002    1.322    0.186     3.968\r\n   .RA               616.541  107.956    5.711    0.000   616.541\r\n   .RS               514.683   86.782    5.931    0.000   514.683\r\n  Std.all\r\n    0.012\r\n    0.029\r\n    0.087\r\n    0.077\r\n\r\nScales y*:\r\n                   Estimate   Std.Err  z-value  P(>|z|)   Std.lv \r\n    Playoffs           1.000                                1.000\r\n  Std.all\r\n    1.000\r\n\r\nR-Square:\r\n                   Estimate \r\n    Playoffs           0.988\r\n    W                  0.971\r\n    RA                 0.913\r\n    RS                 0.923\r\n\r\n\r\n\r\n# Grafické znázornení modelu fungování oaklandských \"Ácek\" \r\nlibrary(semPlot)\r\nsemPaths(fit_oak_model, \r\n         whatLabels=\"std\", \r\n         intercepts=FALSE, \r\n         style=\"lisrel\",\r\n         nCharNodes=0,\r\n         nCharEdges=0,\r\n         curveAdjacent = TRUE,\r\n         title=TRUE,\r\n         layout=\"tree2\",\r\n         curvePivot=TRUE,\r\n         rotation =3)\r\n\r\n\r\n\r\n\r\nVýstupy provedené tzv. pěšinkové analýzy, která je speciálním typem strukturálního modelování, naznačují, že námi navržený model je v souladu s daty, která máme k dispozici (viz “příznivé” hodnoty indexů shody, resp. neshody jako je TLI a CFI, resp. RMSEA, a také vysoké hodnoty standardizovaných regresních koeficientů). Dávají nám tak dobrý důvod věřit, že naše další kroky a rozhodnutí, která založíme na tomto modelu, budou mít žádoucí efekt na požadované výstupy, tj. na postup oaklandských “Áček” do play-off.\r\n6. krok: Intervence\r\nNa základě výše uvedených zjištění začal management oaklandských „Áček“ do svého týmu vybírat hráče, kteří sice nevyhovovali tradičním kritériím, podle kterých hráčští skauti posuzovali kvalitu baseballových hráčů, ale za to vykazovali přesně ty charakteristiky, které podle DePodestových analýz předpovídaly počet vyhraných a prohraných bodů, a potažmo tedy také pravděpodobnost účasti v play-off, která byla hlavním cílem managementu. Díky tomu, že konkurenční týmy důležitost těchto hráčských statistik podceňovaly a naopak přeceňovaly jiné, méně důležité proměnné (např. míru úspěšnosti odpalů, tzv. Batting Average), mohl management oaklandských „Áček“ relativně levně skupovat hráče, kteří jim umožňovali dosahovat stanoveného cíle. Výsledkem bylo to, že oaklandská „Áčka“ vyhrávala zhruba o 20 zápasů za sezónu více než stejně „chudé“ týmy a přibližně stejně tolik zápasů jako 2krát až 3krát bohatší konkurence - viz graf níže.\r\n\r\n\r\n# Nacteme si potrebná data Lahmanovy baseballové databáze, která je verejne prístupná na adrese http://seanlahman.com/baseball-archive/statistics/\r\nmzdyHracu <- read_csv(\"salaries.csv\")\r\nvyhryTymu <- read_csv(\"teams.csv\")\r\n\r\n# Vypocteme si prumernou sumu mezd vyplácených jednotlivými týmy svým hrácum v letech 1998-2001 \r\nprumerna_suma_MezdHracu <- mzdyHracu %>%\r\n  filter(yearID > 1997 & yearID < 2002) %>%\r\n  group_by(teamID) %>%\r\n  summarise(prumerna_suma_MezdHracu = sum(salary)/length(unique(yearID)))\r\n\r\n# Vypocteme si pro jednotlivé týmy prumerný pocet výher za sezónu v letech 1998-2001\r\nprumerny_pocet_vyher <- vyhryTymu %>%\r\n  filter(yearID > 1997 & yearID < 2002) %>%\r\n  group_by(teamID) %>%\r\n  summarise(prumerny_pocet_vyher = sum(W)/length(unique(yearID)))\r\n\r\n# Vyjádreme si graficky vztah mezi poctem výher a množstvím penez, které týmy vynakládají na mzdy svých hrácu  \r\nlibrary(ggrepel)\r\nprumerna_suma_MezdHracu %>%\r\n  left_join(prumerny_pocet_vyher, \"teamID\") %>%\r\n  mutate(OAK = ifelse(teamID == \"OAK\", \"ano\", \"ne\")) %>%\r\n  ggplot(aes(x= prumerna_suma_MezdHracu, y = prumerny_pocet_vyher, fill = OAK)) +\r\n  geom_point()+\r\n  ggtitle(\"Mzdy hrácu a pocet vítezství v letech 1998-2001\")+\r\n  xlab(\"Prumerná suma mezd hrácu (USD)\")+\r\n  ylab(\"Prumerný pocet výher za sezónu\")+\r\n  geom_label_repel(\r\n    aes(label = teamID),\r\n    box.padding = 0.25, point.padding = 0.25,\r\n    segment.color = 'grey50')+\r\n  theme(legend.position=\"none\")+\r\n  scale_fill_manual(values = c(\"#ffd400\", \"#ffffff\"), \r\n                        labels = c(\"ano\",\"ne\"))+\r\n  scale_y_continuous(limits=c(65,100), breaks = seq(65,100,5)) +\r\n  scale_x_continuous(limits=c(2e+07,9e+07), breaks = seq(2e+07,9e+07,1e+07))\r\n\r\n\r\n\r\n\r\nOmezení HR analytiky\r\nPřes veškerou přidanou hodnotu, kterou HR analytika pro organizaci může mít, je vhodné si vůči ní zachovat zdravou míru skepse a být si vědom jejích omezení. Níže uvádím přehled několika z nich.\r\nKvalita a užitečnost výstupů HR analytiky je závislá na kvalitě dat, která do ní vstupují. Jako kdekoli jinde i zde platí okřídlené rčení „rubbish in, rubbish out“. Schopnost získat potřebná data včas, v dostatečné kvalitě a v dostatečném množství přitom představuje jedno z nejužších hrdel celého procesu zavádění HR analytiky v organizacích.\r\nHR analytika pracuje s historickými daty a vychází z předpokladu, že minulost je dobrým prediktorem budoucnosti. Ale jak nás na to opakovaně upozorňují odborníci jako Nassim Taleb nebo Philip Tetlock, tento vztah mezi minulostí a budoucností platí pouze do určité míry a pouze v relativně krátkém časovém horizontu. Na každém rohu na nás číhá nějaká potenciální černá labuť, která může postavit na hlavu všechno, co jsme se na základě našich minulých zkušeností naučili brát jako samozřejmou jistotu.\r\nNe každé prostředí je stejně předvídatelné jako svět sportu. Poměr signálu a šumu se může napříč různými oblastmi významně lišit a čím více převládá náhodný šum nad signálem, tím méně jsou výstupy z HR analytiky užitečné. Příkladem zde může být relativně neúspěšná snaha předpovídat to, jak si baseballové týmu povedou v play-off. Na rozdíl od základní části soutěže, kde se hraje dostatek zápasů na to, aby se vyrušil vliv náhodného štěstí a smůly, v pětizápasových kolech play-off hraje náhoda tak významnou roli, že souvislost mezi celkovým počtem vítězství v základní části a pořadím týmu v play-off je téměř nulová.\r\n\r\n\r\n# Vyfiltrujme si data mezi lety 1994-2011, kdy v play-off hraje 8 týmu.\r\nmoneyball3 <- moneyball %>%\r\n  filter(Year < 2012 & Year > 1993)\r\n  \r\n# Výpocteme si Kendallovu poradovou korelaci mezi mezi celkovýmm poctem vítezství v základní cásti souteže a poradím týmu v play-off mezi lety 1994-2011.  \r\nsuppressWarnings(cor.test(~ W + RankPlayoffs, data = moneyball3, method = \"kendall\"))\r\n\r\n\r\n\r\n    Kendall's rank correlation tau\r\n\r\ndata:  W and RankPlayoffs\r\nz = -0.48318, p-value = 0.629\r\nalternative hypothesis: true tau is not equal to 0\r\nsample estimates:\r\n        tau \r\n-0.05541167 \r\n\r\nČísla mají tu zvláštní moc, že dokážou v člověku velice snadno vzbudit dojem, že toho víme mnohem více než je tomu ve skutečnosti. Je však dobré si být vědom toho, že každá statistická předpověď je vždy zatížena nějakou mírou chyby, tu větší, tu menší. Velkou výhodou statistických modelů je to, že tato chyba je u nich explicitně vyčíslena, takže s ní lze dopředu počítat a zohlednit ji při následném rozhodování. Tato „upřímnost“ ohledně své vlastní omylnosti paradoxně mnohdy staví statistické modely do horšího světla než jinak méně přesné intuitivní úsudky expertů, pro které podobné údaje o míře jejich omylnosti většinou nejsou vůbec k dispozici.\r\nVelikost výhody, kterou nám zavedení HR analytiky dává, může být závislá na tom, zda podobné postupy využívá také naše konkurence. Opět to lze celkem dobře doložit na oaklandských „Áčkách“. Jejich výsledky se mezi lety 2002 až 2012, tj. v době po zveřejnění Moneyballu, kdy již všechny týmy měly příležitost seznámit se s principy prediktivní analytiky a zavést ji do své praxe, začaly více přibližovat výsledkům podobně „chudých“ soupeřů a naopak jejich bohatší soupeři jim svým výkonem zase trochu odskočili - viz graf níže. Z toho mimo jiné vyplývá, že s tím, jak se stále více společností bude při řízení lidských zdrojů spoléhat na výstupy z HR analytiky, přestane být HR analytika nějakou zásadní konkurenční výhodou a stane se z ní něco, co organizaci”pouze\" umožní držet krok s konkurencí.\r\n\r\n\r\n# Vypocteme si prumernou sumu mezd vyplácených jednotlivými týmy svým hrácum v letech 2002-2012 \r\nprumerna_suma_MezdHracu2 <- mzdyHracu %>%\r\n  filter(yearID > 2001 & yearID <= 2012) %>%\r\n  group_by(teamID) %>%\r\n  summarise(prumerna_suma_MezdHracu = sum(salary)/length(unique(yearID)))\r\n\r\n# Vypocteme si pro jednotlivé týmy prumerný pocet výher za sezónu v letech 2002-2012\r\nprumerny_pocet_vyher2 <- vyhryTymu %>%\r\n  filter(yearID > 2001 & yearID <=2012) %>%\r\n  group_by(teamID) %>%\r\n  summarise(prumerny_pocet_vyher = sum(W)/length(unique(yearID)))\r\n\r\n# Vyjádreme si graficky vztah mezi poctem výher a množstvím penez, které týmy vynakládají na mzdy svých hrácu  \r\nprumerna_suma_MezdHracu2 %>%\r\n  left_join(prumerny_pocet_vyher2, \"teamID\") %>%\r\n  mutate(OAK = ifelse(teamID == \"OAK\", \"ano\", \"ne\")) %>%\r\n  ggplot(aes(x= prumerna_suma_MezdHracu, y = prumerny_pocet_vyher, fill = OAK)) +\r\n  geom_point()+\r\n  ggtitle(\"Mzdy hrácu a pocet vítezství v letech 2002-2012\")+\r\n  xlab(\"Prumerná suma mezd hrácu (USD)\")+\r\n  ylab(\"Prumerný pocet výher za sezónu\")+\r\n  geom_label_repel(\r\n    aes(label = teamID),\r\n    box.padding = 0.25, point.padding = 0.25,\r\n    segment.color = 'grey50')+\r\n  theme(legend.position=\"none\")+\r\n  scale_fill_manual(values = c(\"#ffd400\", \"#ffffff\"), \r\n                        labels = c(\"ano\",\"ne\")) +\r\n  scale_y_continuous(limits=c(65,100), breaks = seq(65,100,5)) +\r\n  scale_x_continuous(limits=c(3e+07,2e+08), breaks = seq(3e+07,2e+08,2e+07))\r\n\r\n\r\n\r\n\r\nZávěr\r\nNa příkladu oaklandského baseballového mužstva jsme takto mohli sledovat obvyklý postup aplikace HR analytiky na určitý druh problému, který se snaží v dané organizaci vyřešit. Vzhledem ke specifickému předmětu podnikání oaklandských „Áček“ bylo tímto cílem dosáhnout postupu do play-off a to v situaci, kdy management neměl dostatek finančních prostředků na zaplacení hráčů považovaných dle tradičních měřítek za kvalitní a perspektivní. Od tohoto cíle se potom odvíjela řada kroků, které blíže specifikovaly jeho povahu a identifikovaly faktory (mimo jiné i ty personální), které s jeho dosažením souvisí. Na základě této znalosti potom bylo možné formulovat určité předpovědi a učinit jistá rozhodnutí, která zvýšila pravděpodobnost toho, že se podaří vytčeného cíle dosáhnout. Přestože tento příběh o využití HR analytiky se odehrál ve světě sportu, jeho logika je platná i v kontextu tradičnějšího typu organizací. Ostatně ve všech typech organizací jde nakonec především o to mít na správném místě a ve správný čas ty správné lidi - jedině tak tyto organizace mohou systematicky dosahovat svých strategických cílů.\r\nV několika příštích článcích se podobným způsobem podíváme na to, jak organizace mohu zvýšit šance na dosažení svých strategických cílů prostřednictvím aplikace HR analytiky na takové HR procesy jako je řízení výkonnosti, rozvoj a vzdělávání zaměstnanců, kariérní rozvoj, plánování nástupnictví, monitorování spokojenosti zaměstnanců, change management, nábor a výběr zaměstnanců a jejich onboarding nebo competency management.\r\n\r\n\r\n\r\n",
    "preview": "posts/2018-10-11-moneyball-v-hr-od-hr-analytiky-ke-sportovn-analytice-a-zpt/moneyball-v-hr-od-hr-analytiky-ke-sportovn-analytice-a-zpt_files/figure-html5/unnamed-chunk-10-1.png",
    "last_modified": "2021-01-19T19:56:13+01:00",
    "input_file": "moneyball-v-hr-od-hr-analytiky-ke-sportovn-analytice-a-zpt.utf8.md",
    "preview_width": 1248,
    "preview_height": 768
  }
]
